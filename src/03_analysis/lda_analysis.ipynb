{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "95c0c382-0c5a-4be1-ac02-bddb9fe5060f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "# Latent Dirichlet Allocation (LDA) Modeling ðŸ“Š\n",
    "\n",
    "This notebook explores a sample of the data to try different topic modeling approaches\n",
    "\n",
    "#### Notebook Properties\n",
    "* Upstream Notebook: `src.engineering.word_counts_and_sentiments`\n",
    "* Compute Resources: `32 GB RAM, 4 CPUs`\n",
    "* Last Updated: `Nov 28 2023`\n",
    "\n",
    "#### Data\n",
    "\n",
    "| **Name** | **Type** | **Location Type** | **Description** | **Location** | \n",
    "| --- | --- | --- | --- | --- | \n",
    "| `all_the_news_wc_sentiment` | `input` | `Delta` | WC & Sentiment assigned `AllTheNews` data | `catalog/text_eda/all_the_news.delta` | "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bbb6f810-91e2-440b-a8c4-fe19258c09e2",
     "showTitle": true,
     "title": "Imports"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "from gensim import corpora, models\n",
    "from gensim.utils import simple_preprocess\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "from deltalake import DeltaTable\n",
    "from src.utils.io import FileSystemHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a3e8bcd2-a402-464f-8da3-d8066b57ae14",
     "showTitle": true,
     "title": "Settings"
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.options.plotting.backend = \"plotly\"\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "tqdm.pandas()\n",
    "\n",
    "datafs = FileSystemHandler(\"s3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff253b8e-27a6-4647-80cd-da8fece9aa53",
     "showTitle": true,
     "title": "Input Parameters"
    }
   },
   "outputs": [],
   "source": [
    "LIMIT_PARTITIONS: int | None = None\n",
    "\"\"\"An input parameter to limit the number of table partitions to read from delta. Useful to perform EDA on a sample of data.\"\"\"\n",
    "\n",
    "SHUFFLE_PARTITIONS: bool = False\n",
    "\"\"\"Whether to randomize the partitions before reading\"\"\"\n",
    "\n",
    "INPUT_TABLE: str = \"all_the_news\" \n",
    "INPUT_CATALOG: str = \"text_eda\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a34a7015-491d-4f64-9f75-df722d223d6e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "844dc1dc-2088-4369-adb2-e4cfe858d85d",
     "showTitle": true,
     "title": "Read Input Data"
    }
   },
   "outputs": [],
   "source": [
    "atn_delta_table: DeltaTable = datafs.read_delta(\n",
    "    table=INPUT_TABLE,\n",
    "    catalog_name=INPUT_CATALOG,\n",
    "    as_pandas=False,\n",
    ")\n",
    "\n",
    "df: pd.DataFrame = datafs.read_delta_partitions(\n",
    "    delta_table=atn_delta_table,\n",
    "    N_partitions=LIMIT_PARTITIONS,\n",
    "    shuffle_partitions=SHUFFLE_PARTITIONS,\n",
    ")\n",
    "\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "df = df[df.date < pd.to_datetime(\"2020-04-01\")]\n",
    "df = df.sort_values(by=[\"date\"])\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b2059d6-9a2b-46ec-bc3e-82878aecefdb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sample_df = df[(df.year == 2019) & (df.month == 6)]\n",
    "print(sample_df.shape)\n",
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d0d80c69-b21d-49ea-bd20-0e904439893c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_tokenize(text: str) -> list[str]:\n",
    "    \"\"\"Converts a text string into a set of tokens and removes stopwords and other characters.\"\"\"\n",
    "    return [\n",
    "        token for token in simple_preprocess(text) if token not in stop_words\n",
    "    ]\n",
    "\n",
    "\n",
    "sample_df[\"title_pt\"] = sample_df[\"title\"].dropna().apply(preprocess_tokenize)\n",
    "sample_df[\"article_pt\"] = (\n",
    "    sample_df[\"article\"].dropna().progress_apply(preprocess_tokenize)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4bb158d6-3d4c-4da3-9846-dd46a49aaec5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "92ab459f-1718-4ae6-a7f4-2a1a29b90fc5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sample_df[\"article_pt\"].explode().value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "193abb57-ba8e-4edb-a476-800b5375bd31",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sample_df['title_pt'].explode().value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6059340a-f899-48e9-a0ae-8d263d345687",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Dictionary corpora for LDA\"\"\"\n",
    "# Create a dictionary representation of the documents\n",
    "dictionary: corpora.Dictionary = corpora.Dictionary(sample_df[\"article_pt\"].dropna())\n",
    "\n",
    "#no_below: the token appears in at least these many articles in the data\n",
    "#no_above: Remove tokens that appear in more than x% of documents\n",
    "#keep_n: \n",
    "dictionary.filter_extremes(no_below=10, no_above=0.1, keep_n=100_000)\n",
    "\n",
    "# Create a corpus: a list of bag of words for each document\n",
    "corpus: list[tuple[int, int]] = [\n",
    "    dictionary.doc2bow(doc) for doc in sample_df[\"article_pt\"].dropna()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "572f48ed-127e-45be-be9d-b8400af5371d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "num_topics = 50\n",
    "\n",
    "lda_model = models.LdaMulticore(\n",
    "    corpus,\n",
    "    num_topics=num_topics,\n",
    "    id2word=dictionary,\n",
    "    passes=2,\n",
    "    workers=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e13aa91e-2146-43a6-8298-11828184891d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "topic_words = pd.DataFrame()\n",
    "\n",
    "for i in range(num_topics):\n",
    "    tt = lda_model.get_topic_terms(i, 50)\n",
    "    topic_words[str(i)] = [dictionary[pair[0]] for pair in tt]\n",
    "\n",
    "topic_words.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4acc5755-3856-4146-82e0-b7f8097a2c63",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f51ed0d0-e264-4915-84f1-9b669c0c7255",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Function to get the top topic for each document\n",
    "def format_topics_sentences(\n",
    "    ldamodel=None, corpus=corpus, texts=sample_df[\"article\"]\n",
    ") -> pd.DataFrame:\n",
    "    # Init output\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "\n",
    "    # Get main topic in each document\n",
    "    for i, row in tqdm(enumerate(ldamodel[corpus])):\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = sent_topics_df.append(\n",
    "                    pd.Series([int(topic_num), round(prop_topic, 4), topic_keywords]),\n",
    "                    ignore_index=True,\n",
    "                )\n",
    "            else:\n",
    "                break\n",
    "\n",
    "    sent_topics_df.columns = [\"Dominant_Topic\", \"Perc_Contribution\", \"Topic_Keywords\"]\n",
    "\n",
    "    # Add original text to the end of the output\n",
    "    contents = pd.Series(texts)\n",
    "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "    return sent_topics_df\n",
    "\n",
    "\n",
    "df_topic_sents_keywords = format_topics_sentences(\n",
    "    ldamodel=lda_model, corpus=corpus, texts=sample_df[\"article_pt\"]\n",
    ")\n",
    "\n",
    "# Format\n",
    "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "df_dominant_topic.columns = [\n",
    "    \"Document_No\",\n",
    "    \"Dominant_Topic\",\n",
    "    \"Topic_Perc_Contrib\",\n",
    "    \"Keywords\",\n",
    "    \"Text\",\n",
    "]\n",
    "\n",
    "# Show\n",
    "df_dominant_topic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "16658a08-7174-4ed7-978f-ae425d6ff29a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "lda_analysis",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
