{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d5c95289-cce5-46a5-bfd5-169ba6e83b29",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "# All the News Dataset: Summary EDA ðŸ“Š\n",
    "\n",
    "This is a basic statistical / distribution exploration of the `AllTheNews` dataset. \n",
    "\n",
    "#### Notebook Properties\n",
    "* Upstream Notebook: `src.data_ingestion.all_the_news_v2_ingest`\n",
    "* Compute Resources: `32 GB RAM, 4 CPUs` (when not performing EDA on a sample of data)\n",
    "* Last Updated: `Nov 21 2023`\n",
    "\n",
    "#### Data\n",
    "\n",
    "| **Name** | **Type** | **Location Type** | **Description** | **Location** | \n",
    "| --- | --- | --- | --- | --- | \n",
    "| `all_the_news` | `input` | `Delta` | Read full delta dataset of `AllTheNews` | `catalog/raw/all_the_news.delta` | "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8bf95c3d-fd3b-4c3e-9f83-db6a5448cce2",
     "showTitle": true,
     "title": "Imports"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "from deltalake import DeltaTable\n",
    "from src.utils.io import FileSystemHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "de3d368d-11ae-42ec-a0c0-5cdbba1e779a",
     "showTitle": true,
     "title": "Settings"
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.options.plotting.backend = \"plotly\"\n",
    "\n",
    "datafs = FileSystemHandler(\"s3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "556169de-e6fc-45df-ac1e-f69d3c260f15",
     "showTitle": true,
     "title": "Input Parameters"
    }
   },
   "outputs": [],
   "source": [
    "LIMIT_PARTITIONS: int | None = None\n",
    "\"\"\"An input parameter to limit the number of table partitions to read from delta. Useful to perform EDA on a sample of data.\"\"\"\n",
    "\n",
    "SHUFFLE_PARTITIONS: bool = False\n",
    "\"\"\"Whether to randomize the partitions before reading\"\"\"\n",
    "\n",
    "INPUT_TABLE: str = \"all_the_news\" \n",
    "INPUT_CATALOG: str = \"raw\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "31e2b021-ec5d-47b9-acf8-90dc151b1f42",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a9751aa8-b293-4644-89c8-465540788251",
     "showTitle": true,
     "title": "Read Input Data"
    }
   },
   "outputs": [],
   "source": [
    "atn_delta_table: DeltaTable = datafs.read_delta(\n",
    "    table=INPUT_TABLE,\n",
    "    catalog_name=INPUT_CATALOG,\n",
    "    as_pandas=False,\n",
    ")\n",
    "\n",
    "df: pd.DataFrame = datafs.read_delta_partitions(\n",
    "    delta_table=atn_delta_table,\n",
    "    N_partitions=LIMIT_PARTITIONS,\n",
    "    shuffle_partitions=SHUFFLE_PARTITIONS,\n",
    ")\n",
    "\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "df = df.sort_values(by=[\"date\"])\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eb38a71d-54a7-423c-981f-3f9077ac6f16",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Summary Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0cf83957-82f6-4b5b-9c8f-2514c402f7c6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "#### Publications\n",
    "* 30% of articles appear from Reuters\n",
    "* NYTimes, CNBC & the Hill together make up an additional 25.5%\n",
    "* Remaining publications make up the latter half of all articles\n",
    "\n",
    "> May have to re-randomize accounting for Reuters' imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a9347b5b-a55e-4a85-b7b1-c8f16d414737",
     "showTitle": true,
     "title": "Article Count by Publication"
    }
   },
   "outputs": [],
   "source": [
    "df.publication.value_counts(normalize=True).plot(\n",
    "    kind=\"bar\",\n",
    "    template=\"plotly_white\",\n",
    "    title=\"Article count by Publication\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b5e20051-24f3-4c74-9171-688e908c9a5d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "#### Authors\n",
    "* No bias introduced by authors since they're uniformly distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1de4fdec-78e0-4fda-8cf3-ff99cf4e55b4",
     "showTitle": true,
     "title": "Article Count by Author"
    }
   },
   "outputs": [],
   "source": [
    "df.author.value_counts(normalize=True).head(20).plot(\n",
    "    kind=\"bar\",\n",
    "    template=\"plotly_white\",\n",
    "    title=\"Article count by Author\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "10484d62-187c-4e38-a725-8259ce044664",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "#### Publication Section\n",
    "\n",
    "* 17% of articles come from `World News`, `Business News` and `Market News` sections\n",
    "* Looking at the unique list of sections, there's a wide variety of sections distributed over the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f16f9089-778d-4034-a7c7-bea7d2d87bba",
     "showTitle": true,
     "title": "Article count by Publication Section"
    }
   },
   "outputs": [],
   "source": [
    "df.section.value_counts(normalize=True).head(20).plot(\n",
    "    kind=\"bar\",\n",
    "    template=\"plotly_white\",\n",
    "    title=\"Article count by Publication Section\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f0e70f09-3d29-457a-9818-30439391ee30",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "#### Yeary Articles\n",
    "* `2020` article count is significantly lower (by about half) of the other years' articles\n",
    "* Dataset only has articles until `Apr 2 2020`\n",
    "\n",
    "> May have to consider removing `2020` data also due to covid bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc6cbd16-a164-4d9c-b5cf-b5e4dd91e76e",
     "showTitle": true,
     "title": "Article Count by Year"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Max Date of all Articles:\", df.date.max())\n",
    "\n",
    "df.year.value_counts().sort_index().plot(\n",
    "    kind=\"line\",\n",
    "    template=\"plotly_white\",\n",
    "    markers=True,\n",
    "    title=\"Article Count by Year over Time\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6a37ef84-7c36-48d1-b23a-c79c4acde6d9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "#### Monthly Articles\n",
    "\n",
    "* Fairly non-volatile and standard distribution of articles over time\n",
    "* COVID era has a spike in total count of articles\n",
    "* `Apr 2020` data is not the true minimum count of articles since data only present for first 2 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "20f9028e-66f6-4648-9add-c2dd10a2f185",
     "showTitle": true,
     "title": "Article Count by Month over Time"
    }
   },
   "outputs": [],
   "source": [
    "df.groupby(pd.Grouper(key=\"date\", freq=\"M\"))[\"article\"].count().plot(\n",
    "    kind=\"line\",\n",
    "    template=\"plotly_white\",\n",
    "    markers=True,\n",
    "    title=\"Article Count by Month over Time\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "439aa93c-2ebd-48ef-8962-a89bbbfed17b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "#### Other Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "39f0abeb-0600-4f77-9440-4881337879c5",
     "showTitle": true,
     "title": "Articles over Time by Publication"
    }
   },
   "outputs": [],
   "source": [
    "publication_time_grouped = df.groupby(\n",
    "    [pd.Grouper(key=\"date\", freq=\"M\"), \"publication\"]\n",
    ")[\"article\"].count()\n",
    "\n",
    "publication_time_grouped_unstacked = publication_time_grouped.unstack(\n",
    "    level=\"publication\"\n",
    ")\n",
    "\n",
    "pub_mo_fig = publication_time_grouped_unstacked.plot(\n",
    "    kind=\"line\",\n",
    "    template=\"plotly_white\",\n",
    "    markers=False,\n",
    "    title=\"Articles over Time by Publication\",\n",
    ")\n",
    "pub_mo_fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "33729c31-4d87-4a89-8c1c-4f9af77fb4b5",
     "showTitle": true,
     "title": "[Reuters Discounted] Articles over Time by Publication"
    }
   },
   "outputs": [],
   "source": [
    "publication_time_grouped_disc = (\n",
    "    df[df[\"publication\"] != \"Reuters\"]\n",
    "    .groupby([pd.Grouper(key=\"date\", freq=\"M\"), \"publication\"])[\"article\"]\n",
    "    .count()\n",
    ")\n",
    "\n",
    "publication_time_grouped_disc_unstacked = publication_time_grouped_disc.unstack(\n",
    "    level=\"publication\"\n",
    ")\n",
    "\n",
    "pub_mo_disc_fig = publication_time_grouped_disc_unstacked.plot(\n",
    "    kind=\"line\",\n",
    "    template=\"plotly_white\",\n",
    "    markers=False,\n",
    "    title=\"[Reuters Discounted] Articles over Time by Publication\",\n",
    ")\n",
    "pub_mo_disc_fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "27d63029-d3a1-4eb0-8826-0e14703d851d",
     "showTitle": true,
     "title": "Article Count by Day of Month for all Years"
    }
   },
   "outputs": [],
   "source": [
    "df.day.value_counts().sort_index().plot(\n",
    "    kind=\"bar\",\n",
    "    template=\"plotly_white\",\n",
    "    title=\"Article Count by Day of Month for all Years\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3536a381-f107-4136-8db2-71c9efcece4a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "#### Dense Authors\n",
    "\n",
    "The following authors have written more than 1% of all articles within the publication given the dataset. This is not necessarily a bias, as sometimes one-off op-ed authors could have highly rhetorical sentiments as well. However, it's interesting to see the domination of articles by certain authors as a signal for later.\n",
    "\n",
    "We don't consider authors who have written pieces in multiple publications as some authors could share the same name, and wouldn't represent the authors themselves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee2431e8-9319-43e3-9f87-207354cb21a4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Removes authors like WIRED Staff, or generic author names that are the publication itself\"\"\"\n",
    "author_cleaned_df: pd.DataFrame = df[\n",
    "    df.apply(\n",
    "        lambda row: row.publication.lower() not in row.author.lower()\n",
    "        if not pd.isnull(row.publication) and not pd.isnull(row.author)\n",
    "        else False,\n",
    "        axis=1,\n",
    "    )\n",
    "]\n",
    "\n",
    "print(author_cleaned_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "df69aebb-307b-492e-8f12-4102d2279a6b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "There are certain authors who have written more than 5% of all articles in the dataset. If the dataset is considered a fully representative random sample of all the news out there, then these authors require closer inspection in further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "85d6da42-ba0f-4821-a579-c2de30be5ba8",
     "showTitle": true,
     "title": "Dense Authors per Publication"
    }
   },
   "outputs": [],
   "source": [
    "author_pub_ratio: pd.DataFrame = (\n",
    "    author_cleaned_df\n",
    "    .groupby([\"author\", \"publication\"])\n",
    "    .agg(articles_by_author_for_publication=(\"article\", \"count\"))\n",
    "    .reset_index()\n",
    "    .query(\"articles_by_author_for_publication > 1\")\n",
    "    .merge(\n",
    "        df.groupby([\"publication\"])\n",
    "        .agg(\n",
    "            authors_in_publication=(\"author\", \"nunique\"),\n",
    "            articles_in_publication=(\"article\", \"count\"),\n",
    "        )\n",
    "        .reset_index(),\n",
    "        \"left\",\n",
    "        \"publication\",\n",
    "    )\n",
    ")\n",
    "\n",
    "author_pub_ratio[\"author_ratio_for_publication\"] = (\n",
    "    author_pub_ratio[\"articles_by_author_for_publication\"]\n",
    "    / author_pub_ratio[\"articles_in_publication\"]\n",
    ")\n",
    "author_pub_ratio = author_pub_ratio.round(3)\n",
    "author_pub_ratio = author_pub_ratio.query(\"author_ratio_for_publication > 0.01\")\n",
    "author_pub_ratio = author_pub_ratio.sort_values(\n",
    "    by=[\"author_ratio_for_publication\"], ascending=False\n",
    ")\n",
    "\n",
    "print(author_pub_ratio.shape)\n",
    "author_pub_ratio.head(10)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 4144937806799530,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "all_the_news_summary_eda",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
